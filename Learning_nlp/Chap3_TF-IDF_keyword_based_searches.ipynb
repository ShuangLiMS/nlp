{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bags of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The faster Harry got to the store, the faster Harry, the faster, would get home.\"\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokens = tokernizer.tokenize(sentence.lower())\n",
    "tokens = list(filter(lambda x: x if x not in '- \\t\\n.,;!?' else None, tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'the': 4,\n",
       "         'faster': 3,\n",
       "         'harry': 2,\n",
       "         'got': 1,\n",
       "         'to': 1,\n",
       "         'store': 1,\n",
       "         'would': 1,\n",
       "         'get': 1,\n",
       "         'home': 1})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "bag_of_words = Counter(tokens)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 4), ('faster', 3), ('harry', 2), ('got', 1)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.most_common(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of times a word occurs in a given document is called the term frequency (TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_harry_appears = bag_of_words['harry']\n",
    "num_unique_words = len(tokens)\n",
    "tf = round(times_harry_appears/num_unique_words, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1333"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use term frequency to infer content of paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpia.data.loaders import kite_text\n",
    "tokens = tokenizer.tokenize(kite_text.lower())\n",
    "token_counts = Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "tokens = [x for x in tokens if x not in stopwords and x not in \"(){},.;:'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kite', 16),\n",
       " ('kites', 8),\n",
       " ('wing', 5),\n",
       " ('lift', 4),\n",
       " ('may', 4),\n",
       " ('also', 3),\n",
       " ('kiting', 3),\n",
       " ('flown', 3),\n",
       " ('tethered', 2),\n",
       " ('craft', 2)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kite_counts = Counter(tokens)\n",
    "kite_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07960199004975124, 0.03980099502487562, 0.024875621890547265, 0.01990049751243781, 0.01990049751243781, 0.014925373134328358, 0.014925373134328358, 0.014925373134328358, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.009950248756218905, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453, 0.004975124378109453]\n"
     ]
    }
   ],
   "source": [
    "document_vector = []\n",
    "doc_length = len(tokens)\n",
    "for key, value in kite_counts.most_common():\n",
    "    document_vector.append(value / doc_length)\n",
    "    \n",
    "print(document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpia.data.loaders import harry_docs as docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_tokens = []\n",
    "for doc in docs:\n",
    "    doc_tokens += [sorted(tokenizer.tokenize(doc.lower()))]\n",
    "len(doc_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_doc_tokens = sum(doc_tokens, [])\n",
    "len(all_doc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon = sorted(set(all_doc_tokens))\n",
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " '.',\n",
       " 'and',\n",
       " 'as',\n",
       " 'faster',\n",
       " 'get',\n",
       " 'got',\n",
       " 'hairy',\n",
       " 'harry',\n",
       " 'home',\n",
       " 'is',\n",
       " 'jill',\n",
       " 'not',\n",
       " 'store',\n",
       " 'than',\n",
       " 'the',\n",
       " 'to',\n",
       " 'would']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(',', 0),\n",
       "             ('.', 0),\n",
       "             ('and', 0),\n",
       "             ('as', 0),\n",
       "             ('faster', 0),\n",
       "             ('get', 0),\n",
       "             ('got', 0),\n",
       "             ('hairy', 0),\n",
       "             ('harry', 0),\n",
       "             ('home', 0),\n",
       "             ('is', 0),\n",
       "             ('jill', 0),\n",
       "             ('not', 0),\n",
       "             ('store', 0),\n",
       "             ('than', 0),\n",
       "             ('the', 0),\n",
       "             ('to', 0),\n",
       "             ('would', 0)])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "zero_vector = OrderedDict((token, 0) for token in lexicon)\n",
    "zero_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "doc_vectors = []\n",
    "for doc in docs:\n",
    "    vec = copy.copy(zero_vector)\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    token_counts = Counter(tokens)\n",
    "    for key, value in token_counts.items():\n",
    "        vec[key] = value / len(lexicon)\n",
    "    doc_vectors.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([(',', 0.05555555555555555),\n",
       "              ('.', 0.05555555555555555),\n",
       "              ('and', 0.05555555555555555),\n",
       "              ('as', 0),\n",
       "              ('faster', 0.16666666666666666),\n",
       "              ('get', 0.05555555555555555),\n",
       "              ('got', 0.05555555555555555),\n",
       "              ('hairy', 0),\n",
       "              ('harry', 0.1111111111111111),\n",
       "              ('home', 0.05555555555555555),\n",
       "              ('is', 0),\n",
       "              ('jill', 0),\n",
       "              ('not', 0),\n",
       "              ('store', 0.05555555555555555),\n",
       "              ('than', 0),\n",
       "              ('the', 0.16666666666666666),\n",
       "              ('to', 0.05555555555555555),\n",
       "              ('would', 0.05555555555555555)]),\n",
       " OrderedDict([(',', 0),\n",
       "              ('.', 0.05555555555555555),\n",
       "              ('and', 0.05555555555555555),\n",
       "              ('as', 0),\n",
       "              ('faster', 0.05555555555555555),\n",
       "              ('get', 0),\n",
       "              ('got', 0),\n",
       "              ('hairy', 0.05555555555555555),\n",
       "              ('harry', 0.05555555555555555),\n",
       "              ('home', 0),\n",
       "              ('is', 0.05555555555555555),\n",
       "              ('jill', 0.05555555555555555),\n",
       "              ('not', 0),\n",
       "              ('store', 0),\n",
       "              ('than', 0.05555555555555555),\n",
       "              ('the', 0),\n",
       "              ('to', 0),\n",
       "              ('would', 0)]),\n",
       " OrderedDict([(',', 0),\n",
       "              ('.', 0.05555555555555555),\n",
       "              ('and', 0),\n",
       "              ('as', 0.1111111111111111),\n",
       "              ('faster', 0),\n",
       "              ('get', 0),\n",
       "              ('got', 0),\n",
       "              ('hairy', 0.05555555555555555),\n",
       "              ('harry', 0.05555555555555555),\n",
       "              ('home', 0),\n",
       "              ('is', 0.05555555555555555),\n",
       "              ('jill', 0.05555555555555555),\n",
       "              ('not', 0.05555555555555555),\n",
       "              ('store', 0),\n",
       "              ('than', 0),\n",
       "              ('the', 0),\n",
       "              ('to', 0),\n",
       "              ('would', 0)])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cosine similarity to evaluate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "def cosine_sim(vec1, vec2):\n",
    "    vec1 = [val for val in vec1.values()]\n",
    "    vec2 = [val for val in vec2.values()]\n",
    "    \n",
    "    dot_prod = np.dot(vec1, vec2)\n",
    "    \n",
    "    mag1 = np.sqrt(np.sum(np.square(vec1)))\n",
    "    mag2 = np.sqrt(np.sum(np.square(vec2)))\n",
    "    \n",
    "    return dot_prod/(mag1 * mag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4445004445006667"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(doc_vectors[0], doc_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zipf's law\n",
    "Given some corpus of natural language utterances, the frequency of any word is inversely proportional to its rank in the frequency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/sli/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 69971),\n",
       " ('of', 36412),\n",
       " ('and', 28853),\n",
       " ('to', 26158),\n",
       " ('a', 23195),\n",
       " ('in', 21337),\n",
       " ('that', 10594),\n",
       " ('is', 10109),\n",
       " ('was', 9815),\n",
       " ('he', 9548),\n",
       " ('for', 9489),\n",
       " ('it', 8760),\n",
       " ('with', 7289),\n",
       " ('as', 7253),\n",
       " ('his', 6996),\n",
       " ('on', 6741),\n",
       " ('be', 6377),\n",
       " ('at', 5372),\n",
       " ('by', 5306),\n",
       " ('i', 5164)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "puncs = [',', '.', '--', '-', '!', '?', ':', ';', '``', \"''\", '(', ')', '[', ']']\n",
    "word_list = [x.lower() for x in brown.words() if x not in puncs]\n",
    "token_counts = Counter(word_list)\n",
    "token_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling\n",
    "Inverse Document Frequency, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpia.data.loaders import kite_text, kite_history\n",
    "kite_intro = kite_text.lower()\n",
    "intro_tokens = tokenizer.tokenize(kite_intro)\n",
    "intro_tokens = [x for x in intro_tokens if x not in puncs]\n",
    "kite_history = kite_history.lower()\n",
    "history_tokens = tokenizer.tokenize(kite_history)\n",
    "history_tokens = [x for x in history_tokens if x not in puncs]\n",
    "intro_total = len(intro_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_total = len(history_tokens)\n",
    "hist_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tf = {}\n",
    "hist_tf = {}\n",
    "intro_counts = Counter(intro_tokens)\n",
    "intro_tf['kite'] = intro_counts['kite']/intro_total\n",
    "hist_counts = Counter(intro_tokens)\n",
    "hist_tf['kite'] = hist_counts['kite']/hist_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency of \"kite\" in intro is: 0.0468\n",
      "Term Frequency of \"kite\" in history is: 0.0606\n"
     ]
    }
   ],
   "source": [
    "print('Term Frequency of \"kite\" in intro is: {:.4f}'.format(intro_tf['kite']))\n",
    "print('Term Frequency of \"kite\" in history is: {:.4f}'.format(hist_tf['kite']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to understand inverse document frequency is that if a term appear frequently in a document but occurs rarely in other documents, we could assume that this term is important to that document.\n",
    "\n",
    "#### IDF of a term is the ratio of the total number of documents to the number of documents that the term appears in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf_occ(target_str):\n",
    "    num_docs_containing = 0\n",
    "    for doc in [intro_tokens, history_tokens]:\n",
    "        if target_str in doc:\n",
    "            num_docs_containing += 1\n",
    "    return num_docs_containing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tf['china'] = intro_counts['china'] / intro_total\n",
    "hist_tf['china'] = hist_counts['china'] / hist_total\n",
    "intro_tf['and'] = intro_counts['and'] / intro_total\n",
    "hist_tf['and'] = hist_counts['and'] / hist_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kite': 0.04678362573099415, 'china': 0.0}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kite': 0.06060606060606061, 'china': 0.0}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = {}\n",
    "num_doc = 2\n",
    "idf['china'] = num_doc/idf_occ('china')\n",
    "idf['kite'] = num_doc/idf_occ('kite')\n",
    "idf['and'] = num_doc/idf_occ('and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'china': 2.0, 'kite': 1.0, 'and': 1.0}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tfidf = {}\n",
    "hist_tfidf = {}\n",
    "intro_tfidf['china'] = intro_tf['china'] * idf['china']\n",
    "hist_tfidf['china'] = hist_tf['china'] * idf['china']\n",
    "intro_tfidf['kite'] = intro_tf['kite'] * idf['kite']\n",
    "hist_tfidf['kite'] = hist_tf['kite'] * idf['kite']\n",
    "intro_tfidf['and'] = intro_tf['and'] * idf['and']\n",
    "hist_tfidf['and'] = hist_tf['and'] * idf['and']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'china': 0.0, 'kite': 0.04678362573099415, 'and': 0.029239766081871343},\n",
       " {'china': 0.0, 'kite': 0.06060606060606061, 'and': 0.03787878787878788})"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_tfidf, hist_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the idf different, we use it in log scale\n",
    "\n",
    "### The definition becomes: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $tf(t, d) = \\frac{num-of-occruance(t)}{total-num-words(d)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $idf(t, D) = log(\\frac{total-number-documents}{number-of-documents-containing t})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ tfidf(t, d, D) = tf(t, d) * idf(t, D)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more times that a word appear in documents, the higher tfidf is going to be, while having the term, the document and documents corpus we are studying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Represent document with tfidf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpia.data.loaders import harry_docs as docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The faster Harry got to the store, the faster and faster Harry would get home.',\n",
       " 'Harry is hairy and faster than Jill.',\n",
       " 'Jill is not as hairy as Harry.',\n",
       " 'How long does it take to get to the store?']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "tokenizer = RegexpTokenizer(r'\\w+|$[0-9.]+|\\S+')\n",
    "document_tfidf_vectors = []\n",
    "# Extract corpus of tokens\n",
    "def tokenize_doc(doc):\n",
    "    tokens = tokenizer.tokenize(doc)\n",
    "    tokens = [word for word in tokens if word not in '.,!:;\"\"?']\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_doc = []\n",
    "for doc in docs:\n",
    "    token_doc.append(tokenize_doc(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = []\n",
    "for doc in token_doc:\n",
    "    token_count = {}\n",
    "    token_count = Counter(doc)\n",
    "    token_counts.append(token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(token_count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def tfidf(d, D):\n",
    "    \"\"\"\n",
    "    d: Counter of a single document\n",
    "    D: list of all the documents\n",
    "    \"\"\"\n",
    "    tf_idf = {}\n",
    "    tt_word = sum(d.values())\n",
    "    for word, count in d.items():\n",
    "        tf_d_word = count/tt_word\n",
    "        occ_word = 0\n",
    "        occ_word = sum([1 if word in doc else 0 for doc in D ])\n",
    "#         for single_doc in D:\n",
    "#             if word in single_doc:\n",
    "#                 occ_word+=1\n",
    "        idf_word = np.log(len(D)/occ_word)\n",
    "        tf_idf[word] = tf_d_word * idf_word\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = []\n",
    "for i in range(len(token_counts)):\n",
    "    tf_idf.append(tfidf(token_counts[i], docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('faster', 0.13862943611198905),\n",
       " ('The', 0.09241962407465937),\n",
       " ('got', 0.09241962407465937),\n",
       " ('the', 0.09241962407465937),\n",
       " ('would', 0.09241962407465937),\n",
       " ('home', 0.09241962407465937),\n",
       " ('to', 0.046209812037329684),\n",
       " ('store', 0.046209812037329684),\n",
       " ('and', 0.046209812037329684),\n",
       " ('get', 0.046209812037329684),\n",
       " ('Harry', 0.03835760966023745)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(tfidf(token_counts[0], docs)).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('than', 0.19804205158855578),\n",
       " ('is', 0.09902102579427789),\n",
       " ('hairy', 0.09902102579427789),\n",
       " ('and', 0.09902102579427789),\n",
       " ('faster', 0.09902102579427789),\n",
       " ('Jill', 0.09902102579427789),\n",
       " ('Harry', 0.04109743892168297)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(tfidf(token_counts[1], docs)).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('not', 0.19804205158855578),\n",
       " ('Jill', 0.09902102579427789),\n",
       " ('is', 0.09902102579427789),\n",
       " ('hairy', 0.09902102579427789),\n",
       " ('as', 0.08219487784336595),\n",
       " ('Harry', 0.04109743892168297)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(tfidf(token_counts[2], docs)).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = tokenize_doc(' '.join(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_tfidf = pd.DataFrame(data=None, columns=corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>faster</th>\n",
       "      <th>Harry</th>\n",
       "      <th>got</th>\n",
       "      <th>to</th>\n",
       "      <th>the</th>\n",
       "      <th>store</th>\n",
       "      <th>the</th>\n",
       "      <th>faster</th>\n",
       "      <th>and</th>\n",
       "      <th>...</th>\n",
       "      <th>How</th>\n",
       "      <th>long</th>\n",
       "      <th>does</th>\n",
       "      <th>it</th>\n",
       "      <th>take</th>\n",
       "      <th>to</th>\n",
       "      <th>get</th>\n",
       "      <th>to</th>\n",
       "      <th>the</th>\n",
       "      <th>store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [The, faster, Harry, got, to, the, store, the, faster, and, faster, Harry, would, get, home, Harry, is, hairy, and, faster, than, Jill, Jill, is, not, as, hairy, as, Harry, How, long, does, it, take, to, get, to, the, store]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 39 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(token_counts)):\n",
    "    single_entry = pd.Series(tf_idf[i])\n",
    "    df_tfidf = df_tfidf.append(single_entry, ignore_index=True)\n",
    "df_tfidf.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>faster</th>\n",
       "      <th>Harry</th>\n",
       "      <th>got</th>\n",
       "      <th>to</th>\n",
       "      <th>the</th>\n",
       "      <th>store</th>\n",
       "      <th>the</th>\n",
       "      <th>faster</th>\n",
       "      <th>and</th>\n",
       "      <th>...</th>\n",
       "      <th>How</th>\n",
       "      <th>long</th>\n",
       "      <th>does</th>\n",
       "      <th>it</th>\n",
       "      <th>take</th>\n",
       "      <th>to</th>\n",
       "      <th>get</th>\n",
       "      <th>to</th>\n",
       "      <th>the</th>\n",
       "      <th>store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.038358</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.092420</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.092420</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.092420</td>\n",
       "      <td>0.046210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.069315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       The    faster     Harry      got        to       the     store  \\\n",
       "0  0.09242  0.138629  0.038358  0.09242  0.046210  0.092420  0.046210   \n",
       "1  0.00000  0.099021  0.041097  0.00000  0.000000  0.000000  0.000000   \n",
       "2  0.00000  0.000000  0.041097  0.00000  0.000000  0.000000  0.000000   \n",
       "3  0.00000  0.000000  0.000000  0.00000  0.138629  0.069315  0.069315   \n",
       "\n",
       "        the    faster       and    ...          How      long      does  \\\n",
       "0  0.092420  0.138629  0.046210    ...     0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.099021  0.099021    ...     0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "3  0.069315  0.000000  0.000000    ...     0.138629  0.138629  0.138629   \n",
       "\n",
       "         it      take        to       get        to       the     store  \n",
       "0  0.000000  0.000000  0.046210  0.046210  0.046210  0.092420  0.046210  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.138629  0.138629  0.138629  0.069315  0.138629  0.069315  0.069315  \n",
       "\n",
       "[4 rows x 39 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How long does it take to get to the store?\"\n",
    "token_query = tokenizer.tokenize(query)\n",
    "token_query = [i for i in token_query if i not in \".,;?\"]\n",
    "token_query = Counter(token_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "docs2 = copy.copy(docs)\n",
    "docs2.append(query)\n",
    "query_tfidf = tfidf(token_query, docs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'How': 0.09162907318741552,\n",
       " 'long': 0.09162907318741552,\n",
       " 'does': 0.09162907318741552,\n",
       " 'it': 0.09162907318741552,\n",
       " 'take': 0.09162907318741552,\n",
       " 'to': 0.10216512475319815,\n",
       " 'get': 0.051082562376599076,\n",
       " 'the': 0.051082562376599076,\n",
       " 'store': 0.051082562376599076}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = tokenize_doc(' '.join(docs2))\n",
    "df_tfidf2 = pd.DataFrame(data=None, columns=corpus)\n",
    "for i in range(len(token_counts)):\n",
    "    single_entry = pd.Series(tf_idf[i])\n",
    "    df_tfidf2 = df_tfidf2.append(single_entry, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_entry = pd.Series(query_tfidf)\n",
    "df_tfidf2 = df_tfidf2.append(single_entry, ignore_index=True)\n",
    "df_tfidf2.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>faster</th>\n",
       "      <th>Harry</th>\n",
       "      <th>got</th>\n",
       "      <th>to</th>\n",
       "      <th>the</th>\n",
       "      <th>store</th>\n",
       "      <th>the</th>\n",
       "      <th>faster</th>\n",
       "      <th>and</th>\n",
       "      <th>...</th>\n",
       "      <th>How</th>\n",
       "      <th>long</th>\n",
       "      <th>does</th>\n",
       "      <th>it</th>\n",
       "      <th>take</th>\n",
       "      <th>to</th>\n",
       "      <th>get</th>\n",
       "      <th>to</th>\n",
       "      <th>the</th>\n",
       "      <th>store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.038358</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.092420</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.092420</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.092420</td>\n",
       "      <td>0.046210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.069315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.102165</td>\n",
       "      <td>0.051083</td>\n",
       "      <td>0.051083</td>\n",
       "      <td>0.051083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091629</td>\n",
       "      <td>0.091629</td>\n",
       "      <td>0.091629</td>\n",
       "      <td>0.091629</td>\n",
       "      <td>0.091629</td>\n",
       "      <td>0.102165</td>\n",
       "      <td>0.051083</td>\n",
       "      <td>0.102165</td>\n",
       "      <td>0.051083</td>\n",
       "      <td>0.051083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       The    faster     Harry      got        to       the     store  \\\n",
       "0  0.09242  0.138629  0.038358  0.09242  0.046210  0.092420  0.046210   \n",
       "1  0.00000  0.099021  0.041097  0.00000  0.000000  0.000000  0.000000   \n",
       "2  0.00000  0.000000  0.041097  0.00000  0.000000  0.000000  0.000000   \n",
       "3  0.00000  0.000000  0.000000  0.00000  0.138629  0.069315  0.069315   \n",
       "4  0.00000  0.000000  0.000000  0.00000  0.102165  0.051083  0.051083   \n",
       "\n",
       "        the    faster       and    ...          How      long      does  \\\n",
       "0  0.092420  0.138629  0.046210    ...     0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.099021  0.099021    ...     0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "3  0.069315  0.000000  0.000000    ...     0.138629  0.138629  0.138629   \n",
       "4  0.051083  0.000000  0.000000    ...     0.091629  0.091629  0.091629   \n",
       "\n",
       "         it      take        to       get        to       the     store  \n",
       "0  0.000000  0.000000  0.046210  0.046210  0.046210  0.092420  0.046210  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.138629  0.138629  0.138629  0.069315  0.138629  0.069315  0.069315  \n",
       "4  0.091629  0.091629  0.102165  0.051083  0.102165  0.051083  0.051083  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.41131784, 0.04334664, 0.3134397 , 0.3325787 ],\n",
       "       [0.41131784, 1.        , 0.47135306, 0.        , 0.        ],\n",
       "       [0.04334664, 0.47135306, 1.        , 0.        , 0.        ],\n",
       "       [0.3134397 , 0.        , 0.        , 1.        , 0.99853275],\n",
       "       [0.3325787 , 0.        , 0.        , 0.99853275, 1.        ]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(df_tfidf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use build in libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The faster Harry got to the store, the faster and faster Harry would get home.',\n",
       " 'Harry is hairy and faster than Jill.',\n",
       " 'Jill is not as hairy as Harry.',\n",
       " 'How long does it take to get to the store?']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18 0.   0.   0.55 0.18 0.23 0.   0.3  0.23 0.   0.   0.   0.   0.\n",
      "  0.   0.18 0.   0.   0.55 0.18 0.23]\n",
      " [0.37 0.   0.   0.37 0.   0.   0.37 0.3  0.   0.   0.37 0.   0.37 0.\n",
      "  0.   0.   0.   0.47 0.   0.   0.  ]\n",
      " [0.   0.74 0.   0.   0.   0.   0.29 0.24 0.   0.   0.29 0.   0.29 0.\n",
      "  0.37 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.33 0.   0.26 0.   0.   0.   0.   0.33 0.   0.33 0.   0.33\n",
      "  0.   0.26 0.33 0.   0.26 0.52 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = docs\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "model = vectorizer.fit_transform(corpus)\n",
    "print(model.todense().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitaion of content-based search (tf-idf cosine similarity) is the contraining of using exactly the token work. More specific analysis with small corpus should based on semantics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
